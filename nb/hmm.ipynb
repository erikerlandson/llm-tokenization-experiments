{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efe817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mchmm in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (0.4.5)\n",
      "Requirement already satisfied: tokenizers in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (0.21.4)\n",
      "Requirement already satisfied: datasets in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (4.0.0)\n",
      "Requirement already satisfied: ipywidgets in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (8.1.7)\n",
      "Requirement already satisfied: numpy in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from mchmm) (2.3.2)\n",
      "Requirement already satisfied: scipy in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from mchmm) (1.16.1)\n",
      "Requirement already satisfied: graphviz in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from mchmm) (0.21)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from tokenizers) (0.34.4)\n",
      "Requirement already satisfied: filelock in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (1.1.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: decorator in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/eje/git/llm-tokenization-experiments/.venv/lib64/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mchmm tokenizers datasets ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba120220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split=\"train\")\n",
    "\n",
    "def dataset_iterator(batch_size=1000):\n",
    "    tok_dataset = dataset.select_columns(\"text\")\n",
    "    diter = tok_dataset.iter(batch_size)\n",
    "    for batch in islice(diter, 1000):\n",
    "        yield batch[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ba4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import mchmm as mc\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from transformers import logging\n",
    "\n",
    "logging.enable_progress_bar()\n",
    "logging.set_verbosity_info()\n",
    "\n",
    "def hmm_train_data_iter(dataiter, tokenizer, max_batch=10):\n",
    "    for e in islice(dataiter, max_batch):\n",
    "        for txt in e:\n",
    "            for token in tokenizer.encode(txt).tokens:\n",
    "                yield token\n",
    "def hmm_train_data(dataiter, tokenizer, max_length=1000, max_batch=10):\n",
    "    return list(islice(hmm_train_data_iter(dataiter, tokenizer, max_batch), max_length))\n",
    "\n",
    "def hmm_ascii(max_batch=100, max_length=5000):\n",
    "    alphabet = [str(x) for x in string.printable]\n",
    "    tokenizer = Tokenizer(BPE())\n",
    "    tokenizer.add_tokens(alphabet)\n",
    "    mctrain = hmm_train_data(dataset_iterator(), tokenizer, max_batch=max_batch, max_length=max_length)\n",
    "    hmm = mc.MarkovChain().from_data(mctrain)\n",
    "    return hmm, tokenizer\n",
    "\n",
    "def run_hmm_train(ngram=1, max_batch=100, max_length=5000):\n",
    "    alphabet = [str(x) for x in string.printable]\n",
    "    trainer = BpeTrainer(max_token_length=ngram, show_progress=True, min_frequency=2, initial_alphabet=alphabet)\n",
    "    tokenizer = Tokenizer(BPE())\n",
    "    tokenizer.train_from_iterator(dataset_iterator(), trainer=trainer)\n",
    "    mctrain = hmm_train_data(dataset_iterator(), tokenizer, max_batch=max_batch, max_length=max_length)\n",
    "    hmm = mc.MarkovChain().from_data(mctrain)\n",
    "    return hmm, tokenizer\n",
    "\n",
    "def hmm_generate(hmm, n=100):\n",
    "    _, states = hmm.simulate(n)\n",
    "    return \"\".join(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max_token_length does not seem to be respected, at least for ngram=1\n",
    "hmm_1, tokenizer_1 = hmm_ascii()\n",
    "hmm_5, tokenizer_5 = run_hmm_train(ngram=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af75d778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_1.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4166f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_5.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a86797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' forse h bal chendiedivitad inite ames s @ sils atheg thritenle soreo aminthins areck te , t es ce h'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_generate(hmm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e482071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the capitary 2011 . The game time of the theme about seven goes , is sealed in Japan than expenal role three chosen he abanded edition compation of Gallian original role for potentify while maintaining done by Raita Honce of the Nameless offenders . Ordered by standed by Japan individed and Milities . When time '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_generate(hmm_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5b8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

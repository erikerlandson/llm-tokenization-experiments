{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ca0355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16ac424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\n",
    "    \" \", # alphabet\n",
    "    \"a\",\n",
    "    \"b\",\n",
    "    \"c\",\n",
    "    \"aa\", # other ngrams\n",
    "    \"ab\",\n",
    "    \"ac\",\n",
    "    \"aab\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0925cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.add_tokens(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "231c3c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', ' ', 'b', ' ', 'c']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"a b c\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21c8e136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', ' ', 'b', 'b', ' ', 'c', 'c']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"aa bb cc\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5550f836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'a', ' ', 'aab', ' ', 'aa', 'c']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"aaa, aab, aac\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d47bdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'c', 'c', 'b', 'b', 'c', 'c']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"bccbbcc\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "503c7bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = [\" \", \"a\", \"b\", \"c\"]\n",
    "tokenizer_alphabet = Tokenizer(BPE())\n",
    "tokenizer_alphabet.add_tokens(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59bb564f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_bigrams= [\n",
    "    \" \",\n",
    "    \"a\",\n",
    "    \"b\",\n",
    "    \"c\",\n",
    "    \"  \",\n",
    "    \" a\",\n",
    "    \" b\",\n",
    "    \" c\",\n",
    "    \"a \",\n",
    "    \"aa\",\n",
    "    \"ab\",\n",
    "    \"ac\",\n",
    "    \"b \",\n",
    "    \"ba\",\n",
    "    \"bb\",\n",
    "    \"bc\",\n",
    "    \"c \",\n",
    "    \"ca\",\n",
    "    \"cb\",\n",
    "    \"cc\",\n",
    "]\n",
    "tokenizer_bigrams = Tokenizer(BPE())\n",
    "tokenizer_bigrams.add_tokens(vocab_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6af6d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "toks = random.choices(alphabet, k=1000)\n",
    "corpus = \"\".join(toks)\n",
    "\n",
    "def fertility(tokenizer, corpus):\n",
    "    toks = tokenizer.encode(corpus).tokens\n",
    "    return len(toks) / len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d91177a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fertility(tokenizer_alphabet, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f399e19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fertility(tokenizer, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aad8cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fertility(tokenizer_bigrams, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97eff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
